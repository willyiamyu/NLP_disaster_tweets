{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvs12n5FChcGSGqqC5/ElV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-G-cRmq-9Xd",
        "outputId": "f4c91241-81d2-4289-9262-b07ffbd3c67b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euncXX9Cwo1y"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, RandomSampler, SequentialSampler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIZDBQsHwp4f",
        "outputId": "3f6ee536-18b3-4d84-9335-f90e116d8f85"
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "drive_root = '/gdrive/My Drive/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ea4R9ntwq8n",
        "outputId": "3539cff6-301f-46e0-df92-89ac1e567a3f"
      },
      "source": [
        "%cd ..\n",
        "%cd gdrive/MyDrive/disaster_nlp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/gdrive/MyDrive/disaster_nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc2rvY9Ww8sN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a60040d-32ab-410b-d164-0cb27928690f"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "ids = test.id\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj6fHGtpMLdY"
      },
      "source": [
        "# function to remove html tags in text\n",
        "def htmlremove(text):\n",
        "    return re.sub('<[^<]+?>', '', text)\n",
        "\n",
        "train['text'] = train['text'].apply(htmlremove)\n",
        "test['text'] = test['text'].apply(htmlremove)  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKhHzBgTMNRX"
      },
      "source": [
        "# remove url and @'s\n",
        "def urlremove(text):\n",
        "    return re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
        "\n",
        "train['text'] = train['text'].apply(urlremove)\n",
        "test['text'] = test['text'].apply(urlremove)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM0ni7SQMPk9"
      },
      "source": [
        "# remove emojis\n",
        "# https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
        "        u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
        "        u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
        "        u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
        "        u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
        "        \"+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "train['text'] = train['text'].apply(remove_emoji)\n",
        "test['text'] = test['text'].apply(remove_emoji)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8loLizNMSNj"
      },
      "source": [
        "# remove contractions\n",
        "# taken from: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
        "def decontracted(text):\n",
        "    if '’' in text:\n",
        "        text = text.replace(\"’\", \"'\")\n",
        "    # specific\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "\n",
        "    # general\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text\n",
        "\n",
        "train['text'] = train['text'].apply(decontracted)\n",
        "test['text'] = test['text'].apply(decontracted)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbFKj_QGMV5w"
      },
      "source": [
        "# remove special characters\n",
        "def characterremove(text):\n",
        "    return re.sub('\\W+|_', ' ', text)\n",
        "\n",
        "train.text = train.text.apply(characterremove)\n",
        "test.text = test.text.apply(characterremove)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9HZ7oT-MYBH"
      },
      "source": [
        "# remove numbers in text\n",
        "def remove_numbers(text):\n",
        "    # define the pattern to keep\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
        "    return re.sub(pattern, '', text)\n",
        "\n",
        "train.text = train.text.apply(remove_numbers)\n",
        "test.text = test.text.apply(remove_numbers)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-UOpxYJMa-z"
      },
      "source": [
        "train.text = train.text.str.lower()\n",
        "train.text = train.text.str.strip()\n",
        "\n",
        "test.text = test.text.str.lower()\n",
        "test.text = test.text.str.strip()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTuzFcpyMbvT",
        "outputId": "2c7eaafd-f5f8-4131-f6d5-23a55abd8050"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))  \n",
        "lemmer = WordNetLemmatizer()\n",
        "train.text = [' '.join([lemmer.lemmatize(word) for word in text.split(' ') if word not in stop_words]) for text in train.text]\n",
        "\n",
        "test.text = [' '.join([lemmer.lemmatize(word) for word in text.split(' ') if word not in stop_words]) for text in test.text]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "U9Mp3PZAZnZR",
        "outputId": "5a699bc3-88d8-4176-89d4-3d203d6ba93a"
      },
      "source": [
        "lens = []\n",
        "for tweet in train.text:\n",
        "  lens.append(len(tweet))\n",
        "\n",
        "plt.hist(lens, bins='auto')\n",
        "plt.title('Tweet Length Distribution')\n",
        "plt.tight_layout()\n",
        "print('average tweet length: {}'.format(np.mean(lens)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average tweet length: 58.47773545251543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKoiiYohxvhR"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = transformers.BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6_RoehvQ0cA"
      },
      "source": [
        "# define Dataset class\n",
        "class TorchDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, tokenizer, max_length):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_mask = []\n",
        "    self.segment_ids = []\n",
        "    self.target = tweets.target.to_numpy()\n",
        "\n",
        "    for tweet in tweets.text:\n",
        "      # tokenizing on a word level\n",
        "      # encodings is dictionary with 3 keys:\n",
        "      # one are the tokenized inputs, one are attention_masks (what to pay attention to), and one is to determine which sequence\n",
        "      # all tweets are padded to length of 'max_length' w/ the pad token\n",
        "      # padded tokens are defaulted w/ attention 0\n",
        "      encodings = tokenizer(tweet, truncation=True, max_length=MAX_LEN, padding=\"max_length\")\n",
        "      self.input_ids.append(torch.tensor(encodings['input_ids']))\n",
        "      self.attn_mask.append(torch.tensor(encodings['attention_mask']))\n",
        "      self.segment_ids.append(torch.tensor(encodings['token_type_ids']))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {'input_ids': self.input_ids[idx], 'attn_mask': self.attn_mask[idx], 'segment_ids': self.segment_ids[idx], 'labels': self.target[idx]}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "b__59P3aFfg6",
        "outputId": "2b7d0d8c-5153-4f4a-f560-45f64783ffff"
      },
      "source": [
        "MAX_LEN = 140\n",
        "dataset = TorchDataset(train, tokenizer, MAX_LEN)\n",
        "tokenizer.decode((list(dataset))[0]['input_ids'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] deed reason earthquake may allah forgive u [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiyWcGm8Fgvy"
      },
      "source": [
        "TRAIN_SIZE = int(0.85 * len(dataset))\n",
        "VAL_SIZE = len(dataset) - TRAIN_SIZE\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [TRAIN_SIZE, VAL_SIZE])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Ybuq8vOHQA"
      },
      "source": [
        "# DataLoader similar to tfdatset, shuffle and batch \n",
        "# train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE) \n",
        "# for train, shuffle and batch randomly\n",
        "BATCH_SIZE = 8\n",
        "train_dataloader = DataLoader(train_ds, \n",
        "                              sampler = RandomSampler(train_ds), \n",
        "                              batch_size = BATCH_SIZE)\n",
        "\n",
        "# for validation can just batch sequentially.\n",
        "val_dataloader = DataLoader(val_ds,\n",
        "            sampler = SequentialSampler(val_ds),\n",
        "            batch_size = BATCH_SIZE)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ0VQ22xWDUw"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.bert = bert_model\n",
        "    self.drop = nn.Dropout(p=0.1)\n",
        "    # dense layer\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 2)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    hidden_state, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frfjKoYRWMqi",
        "outputId": "f123e301-f195-4ad9-b710-19bd3153dfc3"
      },
      "source": [
        "model = Classifier()\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtz0H9CWhB1D"
      },
      "source": [
        "epochs = 2\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "# slowly tune with warm-up steps (use a low learning rate)\n",
        "# then transition to initialized lr after the 100 steps are over\n",
        "warmup_steps = 0\n",
        "\n",
        "# change learning rate as throughout training loop\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9szhmVljhT68"
      },
      "source": [
        "def train_epoch(model, dataloader, loss_fn, optimizer):\n",
        "  num_correct = 0\n",
        "  losses = []\n",
        "  for d in dataloader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attn_mask = d['attn_mask'].to(device)\n",
        "    targets = d['labels'].to(device)\n",
        "    outputs = model(input_ids=input_ids, attention_mask = attn_mask)\n",
        "    # max logit for pred\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    num_correct += torch.sum(preds==targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    # clip gradient to avoid exploding gradient \n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    # reset gradients after each batch\n",
        "    # same as model.zero_grad since optimizer utilizing model params\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return num_correct.double() / len(train_ds), np.mean(losses)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YthurTgL0HYv"
      },
      "source": [
        "def eval_epoch(model, dataloader, loss_fn):\n",
        "  num_correct = 0\n",
        "  losses = []\n",
        "  model = model.eval()\n",
        "  for d in dataloader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attn_mask = d['attn_mask'].to(device)\n",
        "    targets = d['labels'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids=input_ids, attention_mask = attn_mask)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      num_correct += torch.sum(preds==targets)\n",
        "      losses.append(loss.item())\n",
        "      \n",
        "  return num_correct.double() / len(val_ds), np.mean(losses)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L3HvPgjFgUS",
        "outputId": "2cb13ba0-d1dd-48a2-f95d-2d5b827823dd"
      },
      "source": [
        "#train loop\n",
        "from collections import defaultdict\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "  print(f'Epoch {epoch}/{epochs}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model, train_dataloader, loss_fn, optimizer)\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_epoch(model, val_dataloader, loss_fn)\n",
        "  print(f'Val loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_acc = val_acc\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "----------\n",
            "Train loss 0.45538571737108036 accuracy 0.7957039097511978\n",
            "Val loss 0.41538238936996125 accuracy 0.8231173380035026\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "b-8njqAdcLwL",
        "outputId": "b45538ab-44d6-482e-c6a8-985755db758e"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
        "ax[0].plot(range(1, epochs+1), history['train_acc'], label='train_acc')\n",
        "ax[0].plot(range(1, epochs+1), history['val_acc'], label='val_acc')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(range(1, epochs+1), history['train_loss'], label='train_loss')\n",
        "ax[1].plot(range(1, epochs+1), history['val_loss'], label='val_loss')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFiDOtSknYWR"
      },
      "source": [
        "# define Dataset class\n",
        "class TestDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, tokenizer, max_length):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_mask = []\n",
        "    self.segment_ids = []\n",
        "\n",
        "    for tweet in tweets.text:\n",
        "      # tokenizing on a word level\n",
        "      # encodings is dictionary with 3 keys:\n",
        "      # one are the tokenized inputs, one are attention_masks (what to pay attention to), and one is to determine which sequence\n",
        "      # all tweets are padded to length of 'max_length' w/ the pad token\n",
        "      # padded tokens are defaulted w/ attention 0\n",
        "      encodings = tokenizer(tweet, truncation=True, max_length=MAX_LEN, padding=\"max_length\")\n",
        "      self.input_ids.append(torch.tensor(encodings['input_ids']))\n",
        "      self.attn_mask.append(torch.tensor(encodings['attention_mask']))\n",
        "      self.segment_ids.append(torch.tensor(encodings['token_type_ids']))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {'input_ids': self.input_ids[idx], 'attn_mask': self.attn_mask[idx], 'segment_ids': self.segment_ids[idx]}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F1Ee4efrN6m"
      },
      "source": [
        "test_dataset = TestDataset(test, tokenizer, MAX_LEN)\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset),\n",
        "            batch_size = BATCH_SIZE)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLqHfJo12qtO"
      },
      "source": [
        "model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "\n",
        "predictions = []\n",
        "for d in test_dataloader:\n",
        "  input_ids = d['input_ids'].to(device)\n",
        "  attn_mask = d['attn_mask'].to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask = attn_mask)\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    predictions.append(preds)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEXKUdq9w3RG"
      },
      "source": [
        "flat_predictions = [item.tolist() for sublist in predictions for item in sublist]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIZS_Grk3-h1"
      },
      "source": [
        "test['target']= flat_predictions"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jD43yNxg5WM0",
        "outputId": "cd47d880-fea9-4f13-c606-cdb2d3ea8c78"
      },
      "source": [
        "from google.colab import files\n",
        "test_export = test.loc[:, ['id', 'target']]\n",
        "test_export.to_csv('bert_1.csv', index=False) \n",
        "files.download('bert_1.csv')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b43d346a-a2ce-4723-958f-bb93be35dd46\", \"bert_1.csv\", 22746)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}